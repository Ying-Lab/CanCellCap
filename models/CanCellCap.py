import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np 
from .moe import MoE
from torch.autograd import Function

my_alpha = 2

class ReverseLayerF(Function):

    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha

        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        output = grad_output.neg() * ctx.alpha

        return output, None


# a FcNet 
class FcNet(nn.Module):
    def __init__(self,in_size:int = 4096, mid_size:int = 512):
        """
        A full connected network
        
        Args:
            args (object) : args object generated by opt_util.py
            mid_size (int) : The bottleneck layer size of the network
        """
        super(FcNet, self).__init__()
        self.desen_layer = nn.Sequential(
            nn.Linear(in_size, int(in_size)),
            nn.Dropout(),
            nn.Linear(int(in_size), mid_size),
            nn.Dropout()
        )
        self.out_size=mid_size
    def forward(self,x):
        x = self.desen_layer(x)
        return x
    
def get_fea(args):
    return FcNet(in_size=len(args.HVG_list))

def mask_decoder(args, in_size):
    return FcNet(in_size=in_size, mid_size=len(args.HVG_list))



class feat_classifier(nn.Module):
    def __init__(self, class_num, bottleneck_dim=512):
        """
        A classification layer

        Args:
            class_num (int) : Number of classes.
            bottleneck_dim (int) : The input size of the classification layer
        """
        super(feat_classifier, self).__init__()
        self.fc = nn.Linear(bottleneck_dim, class_num)
    def forward(self, x):
        x = self.fc(x)
        return x

class ad_classifier_class(nn.Module):
    def __init__(self, class_num, bottleneck_dim=512):
        """
        A classification layer

        Args:
            class_num (int) : Number of classes.
            bottleneck_dim (int) : The input size of the classification layer
        """
        super(ad_classifier_class, self).__init__()
        self.classifier_layer = nn.Sequential(
            nn.Linear(bottleneck_dim, class_num),
            nn.LogSoftmax(dim=1)
        )
    def forward(self, x):
        x = self.classifier_layer(x)
        return x


class CanCellCap(nn.Module):
    def __init__(self, args):
        """
        The network contains a feature extractor and a classifier
        Args:
            args (object) : args object generated by opt_util.py
        """
        super(CanCellCap, self).__init__()
        self.featurizer = get_fea(args)
        self.model_name = 'common_moe_mask'
        self.moe = MoE(args.num_tissue, len(args.HVG_list), self.featurizer.out_size)
        self.tissue_classifier = feat_classifier(args.num_tissue, self.featurizer.out_size)
        self.ad_classifier = ad_classifier_class(args.num_tissue, self.featurizer.out_size)
        self.common_featurizer = get_fea(args)

        self.mask_decoder = mask_decoder(args, self.common_featurizer.out_size*2)
        self.classifier = feat_classifier(args.num_classes, self.featurizer.out_size*2)


        self.cancer_type_classifier = feat_classifier(args.num_cancer_type, self.featurizer.out_size)
        self.MSE = nn.MSELoss()
        # self.tissue_embedding_layer = nn.Embedding(num_embeddings=10, embedding_dim=5)
        self.register_buffer('update_count', torch.tensor([0]))
        self.args = args

    def data_aug(self, data, noise_factor=0.05):
        mask = (torch.rand(data.size()) > self.args.gene_drop_weight).float().cuda()
        data = data * mask
        return data
        
    def update(self, minibatches, opt, sch):

        all_x_ori = torch.cat([data[0].cuda().float() for data in minibatches])

        if self.args.gene_drop_weight:
            all_x = self.data_aug(all_x_ori)
        else:
            all_x = all_x_ori


        all_logits, y_tissue, y_common_domain, all_x_reconstruct = self.predict(all_x)

        all_logits_idx = 0
        cancer_losses = torch.zeros(len(minibatches))
        tissue_losses = torch.zeros(len(minibatches))
        ad_losses = torch.zeros(len(minibatches))
        reconstruct_losses = torch.zeros(len(minibatches))
        for i, data in enumerate(minibatches):
            x_ori = all_x_ori[all_logits_idx:all_logits_idx +
                                data[0].shape[0]]
            x_reconstruct = all_x_reconstruct[all_logits_idx:all_logits_idx +
                                data[0].shape[0]]
            logits = all_logits[all_logits_idx:all_logits_idx +
                                data[0].shape[0]]
            tissue_logit = y_tissue[all_logits_idx:all_logits_idx +
                                data[0].shape[0]]
            common_domain_logit = y_common_domain[all_logits_idx:all_logits_idx +
                                data[0].shape[0]]
            all_logits_idx += data[0].shape[0]

            cancer_loss = F.cross_entropy(logits, data[1].cuda().long())
            tissue_loss = F.cross_entropy(tissue_logit, data[2].cuda().long())
            ad_loss = F.cross_entropy(common_domain_logit,  data[2].cuda().long())
            reconstruct_loss = self.MSE(x_reconstruct, x_ori)

            cancer_losses[i] = cancer_loss
            tissue_losses[i] = tissue_loss
            ad_losses[i] = ad_loss
            reconstruct_losses[i] = reconstruct_loss

        cancer_mean = cancer_losses.mean() 
        tissue_mean = self.args.weight_tissue * tissue_losses.mean()
        ad_mean = self.args.weight_ad_train * ad_losses.mean()
        reconstruct_mean = self.args.weight_reconstruct * reconstruct_loss.mean()

        # penalty = ((cancer_losses - cancer_mean) ** 2).mean()
        loss = cancer_mean + tissue_mean +  ad_mean + reconstruct_mean#+ penalty_weight * penalty
        # loss = ad_mean
        opt.zero_grad()
        loss.backward()
        # breakpoint()
        opt.step()
        if sch:
            sch.step()
        self.update_count += 1
   
        return {'loss': loss.item(),'cancer_mean': cancer_mean.item(), 'tissue_mean':tissue_mean.item(), 'ad_mean':ad_mean.item(), 'reconstruct_mean':reconstruct_mean.item()}


    def predict(self, x):
        x_hidden = self.featurizer(x)
        moe_wight = self.tissue_classifier(x_hidden)
        x_moe = self.moe(x, moe_wight)

        x_common = self.common_featurizer(x)
        x_cat = torch.cat([x_common,x_moe],dim=1)

        logit = self.classifier(x_cat)
        
        reverse_feature = ReverseLayerF.apply(x_common, my_alpha)

        logit_common_domain = self.ad_classifier(reverse_feature)

        x_reconstruct = self.mask_decoder(x_cat)
        return logit, moe_wight, logit_common_domain, x_reconstruct
        
    def infer(self, x):
        x_hidden = self.featurizer(x)
        moe_wight = self.tissue_classifier(x_hidden)
        x_moe = self.moe(x, moe_wight)

        x_common = self.common_featurizer(x)
        x_cat = torch.cat([x_common,x_moe],dim=1)

        logit = self.classifier(x_cat)

        return logit
